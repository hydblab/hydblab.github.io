---
layout: post
title: "테스트와바이트"
author: "Polishedwh"
---

## 텍스트와 바이트

### 문자 문제
- string은 문자의 연속을
- 문자형식으로 인한 문제가 있다．

~~~
Example 4-1. Encoding and decoding.
>>> s = 'café'
>>> len(s) #
4
>>> b = s.encode('utf8') #
>>> b
b'caf\xc3\xa9' #
>>> len(b) #
5
>>> b.decode('utf8') #
'café'
~~~

- str은 4개의 유니코드 문자지만 인코딩하게되면 5바이트로 바뀐다．
- é가 utf-8에서 ２바이트를 차지하기때문이다．

### 바이트에 대한 기본 지식
- python3에는 ２가지 바이너리 시퀀스 타입이 있다．
- 불변 bytes(py3.0)， 가변 bytearray(py2.6)

~~~
Example 4-2. A five-byte sequence as bytes and as bytearray.
>>> cafe = bytes('café', encoding='utf_8')
>>> cafe
b'caf\xc3\xa9'
>>> cafe[0]
99
>>> cafe[:1] 
b'c'
>>> cafe_arr = bytearray(cafe)
>>> cafe_arr
bytearray(b'caf\xc3\xa9')
>>> cafe_arr[-1:]
bytearray(b'\xa9')
~~~

- bytes는 range(256)의 정수로 표현됨
- 반면 bytearray는 슬라이싱 해도 bytearray로 나타남
- 다시말해 길이가 1인 bytes 객체를 반환한다．(예외적으로 ==를 사용 할 수 있다．）
- 바이트 값은 값에 따라 세가지로 표현 할 수 있다.
- 화면에 표시 가능한 문자는 문자 그대로 표현한다.
- 개행, cr, tab 등은 \t 등의 형태로 출력
- 나머지는 \00 처럼 16진수로 출력
- bytes, bytearray는 format(), format_map()제외하고 모두 지원한다.

### 기본 인코더/ 디코더
- utf-8외에도 다른 포멧의 텍스트 포멧을 encoding/decoding 할 수 있는 코덱을 포함하고 있다.
- utf-8 인코딩은 모든 유니코드 코드 포인트를 처리 할 수 있다.

### 인코딩/ 디코딩 문제 이해하기

#### UnicodeEncodeError
- 인코딩중 대상 문자가 없을 때 오류처리를 별도로 지정하지 않았다면 이 오류가 발생한다.
- ignore는 무시, replace는 ?로 치환, xmlcharrefreplace는 xml 개체로 치환한다.

~~~
Example 4-6. Encoding to bytes: success and error handling

>>> city = 'São Paulo'
>>> city.encode('utf_8')
b'S\xc3\xa3o Paulo'
>>> city.encode('utf_16')
b'\xff\xfeS\x00\xe3\x00o\x00 \x00P\x00a\x00u\x00l\x00o\x00'
>>> city.encode('iso8859_1')
b'S\xe3o Paulo'
>>> city.encode('cp437')
Traceback (most recent call last):
 File "<stdin>", line 1, in <module>
 File "/.../lib/python3.4/encodings/cp437.py", line 12, in encode
 return codecs.charmap\_encode(input,errors,encoding\_map)
 UnicodeEncodeError: 'charmap' codec can't encode character '\xe3' in
 position 1: character maps to <undefined>
>>> city.encode('cp437', errors='ignore')
b'So Paulo'
>>> city.encode('cp437', errors='replace')
b'S?o Paulo'
>>> city.encode('cp437', errors='xmlcharrefreplace')
b'S&#227;o Paulo'
~~~

#### UnicodeDecodeError
- 바이트 시퀀스가 텍스트 문자로 변환 할 수 없을때 발생한다.
- 8비트 코덱(cp1252, iso8859\_1) 등은 멋대로 오류없이 디코딩하므로 주의가 필요하다.

#### 예상과 달리 인코딩된 모듈을 로딩할 때 발생하는 SyntaxError
- 파이썬은 2.5는 아스키, 3부터는 utf-8을 소스 코드 기본 인코딩 방식으로 사용한다.
- 인코딩 선언이 필요하다(# coding: utf-8. 없을 경우 오류가 발생 할 수 있다.

#### 바이트 인코딩 알아내는 방법
- 없다.
- 경험적인 방법을 통해 유추하거나 Chardet 모듈을 통해 30가지 정도는 확인 할 수 있다.
- b'\x20\x00' 바이트 시퀀스가 자주 나타난다면 utf-16le 인코딩에서 공백 문자일 가능 성이 있다 등.

#### BOM(Byte Order Mark)
- utf-16에서 빅엔디안과 리틀엔디안 구분에 사용된다.
 - 엔디언 문제는 utf-16, utf-32에만 영향이 있고, utf-8에는 영향을 주지 않는다.
 - 엔디언 특성과 상관없이 동일한 바이트 시퀀스를 생성하기 때문
 - zero width no-brak space(U+FFF)를 인코딩된 텍스트 앞에 붙인다.
 - 출력으로는 보이지 않으면 이 문자가 없다면 리틀엔디안으로 본다.
 - 리틀엔디안에서는 U+FFF가 b'\xff\xfe'로 나타난다.
  - utf-16le, utf-16be등 변형된 형태로 명시하는 경우가 있는데 이때는 U+FFF를 제거하고 가져온다.

### 텍스트 파일 다루기
- 입력할때 bytes를 str로 변환한다.
- str객체로 로직을 수행한다.
- str을 bytes로 변환해서 출력한다.
- python 3에서는 open()에서 알아서 해준다.

- open()
 - open()시 인코딩에 주의하자, 파일을 인코딩한 형태로 오픈해야한다.
 - open()할때는 인코딩을 지정해서 하자, 기본 인코딩은 os마다 다를 수 있기 때문이다.

- 기본 인코딩
 - 기본 인코딩은 사용하지 않는편이 낫다.
 - 기본 인코딩 설정은 윈도우(다양)와 리눅스(utf-8)의 경우에 많은 부분에서 다르다.
  - locale.getpreferredencoding() 함수가 반환하는 설정이 중요하다. 텍스트 파일을 열 때 기본적으로 사용되기 때문이다.
  - locale.getpreferredencoding() 마저도 참고 할만한 값일 뿐이기때문에 기본인코딩은 사용하지 않는것이 좋다.

### 제대로 비교하기 위해 유니코드 정규화하기
- 유니코드 표준에는 é와 'e\u0301'을 동일하다고 명시하지만 파이썬에서는 다르다고 인식한다.
- unicodedata.normalize()함수가 제공하는 유니코드 정규화로 해결한다.

- 일반 문자
- NFD로의 정규화 : 코드를 정준 분해한다
 - NFD: 발음기호가 있는 문자 => 발음기호+ 문자
 - À (U+00C0) → A (U+0041) + ̀ (U+0300)

- NFC로의 정규화 : 코드를 정준 분해한 뒤에 다시 정준 결합한다.
 - NFC: 발음기호+ 문자 => 발음기호가 있는 문자(NFD로 분해한 뒤 다시 결합)
 - A (U+0041) + ̀ (U+0300) → À (U+00C0)

- 호환 문자
 - NFKD로의 정규화 : 코드를 호환 분해한다.
 - 합자 처리된 알파벳 코드를 각 알파벳으로 분해하기
  - ﬁ (U+FB01) → f (U+0066) + i (U+0069)
  - 옛 알파벳을 현대 알파벳으로 바꾸기
  - ſ (U+017F) → s (U+0073)

- NFKC로의 정규화 : 코드를 호환 분해한 뒤에 다시 정준 결합한다.
 - 발음 구별 기호가 있는 옛 알파벳을 현대 알파벳으로 바꾸기
 - ẛ (U+1E9B) → ṡ (U+1E61)

#### 케이스 폴딩
- 모든 문자를 소문자로 변환한다.
- str.casefold()를 사용한다.
- 조금 변하는 유니코드 문자가 있다.
- str.casefold()와 str.lower()가 다른 경우가 116개 있다.
- 유니코드를 비교 할 때 nfc\_equal(), fold\_equl() 등의 도구를 이용 할 수도 있다.

#### 발음기호 제거하기
- 발음 기호를 제거해서 사용하는 방법도 때로는(url등)에서 유용할 수 있다.
- 발음 기호를 건너 뛰는 방법
- NFD로 분해 후 발음기호를 건너 뛴다.

~~~
import unicodedata
import string
def shave_marks(txt):
    """Remove all diacritic marks"""
    norm_txt = unicodedata.normalize('NFD', txt)
    shaved = ''.join(c for c in norm_txt

    if not unicodedata.combining(c))
        return unicodedata.normalize('NFC', shaved)

- 그리스 문자도 변경한다.
def shave\_marks\_latin(txt):
    """Remove all diacritic marks from Latin base characters"""
    norm_txt = unicodedata.normalize('NFD', txt)
    latin_base = False
    keepers = []
    for c in norm_txt:
        if unicodedata.combining(c) and latin_base:
            continue # ignore diacritic on Latin base char
            keepers.append(c)

             \\if it isn't combining char, it's a new base char
        if not unicodedata.combining(c):
            latin_base = c in string.ascii_letters
            shaved = ''.join(keepers)
            return unicodedata.normalize('NFC', shaved) 

- 기호를 아스키로 모두 바꿔버린다.

~~~~
Example 4-17. Transform some Western typographical symbols into ASCII. This snip‐
pet is also part of sanitize.py from Example 4-14.

single\_map = str.maketrans("""‚ƒ„†ˆ‹‘’“”•–—˜›""",
                                                                                                                                                """'f"*^<''""---~>""")
multi\_map = str.maketrans({
              '€': '<euro>',
              '…': '...',
              'Œ': 'OE',
              '™': '(TM)',
              'œ': 'oe',
              '‰': '<per mille>',
              '‡': '**',
          })

multi\_map.update(single\_map)

def dewinize(txt):
    """Replace Win1252 symbols with ASCII chars or sequences"""
    return txt.translate(multi_map)
def asciize(txt):
    no_marks = shave_marks_latin(dewinize(txt))
    no_marks = no_marks.replace('ß', 'ss')
    return unicodedata.normalize('NFKC', no_marks) 
~~~

### 유니코드 텍스트 정렬하기
- 파이썬에서는 항목 하나 하나를 비교한다.
- 유니코드 정렬시에는 문제가 발생 할 수 있다.

- 파이썬에서 비 아스키 문자는 locale.strxfrm()함수를 이용해서 변환 하는 것이 표준이다.
- 문자열을 현지어와 비교해서 사용할 수 있는 문자열로 변경한다.

- 단, 어플리케이션에서 현지어를 설정(setlocale)하고 os가 지원 해야 한다.
 - 시스템 전역에 영향을 미치므로 신중해야 한다.
 - os에서 setlocale을 제대로 구현하지 않았을 수도 있다.

#### 유니코드 대조 알고리즘을 이용한 정렬
- PyUCA를 사용한다.
- 지역 정보를 고려하지 않으며 정렬 방식을 커스터마이즈 할 수 있다.

~~~
Example 4-20. Using the pyuca.Collator.sort\_key method.

>>> import pyuca
>>> coll = pyuca.Collator()
>>> fruits = ['caju', 'atemoia', 'cajá', 'açaí', 'acerola']
>>> sorted\_fruits = sorted(fruits, key=coll.sort\_key)
>>> sorted\_fruits
['açaí', 'acerola', 'atemoia', 'cajá', 'caju']
~~~

#### 유니코드 대조 알고리즘을 이용한 정렬
- PyUCA를 사용한다.
- 지역 정보를 고려하지 않으며 정렬 방식을 커스터마이즈 할 수 있다.

~~~
Example 4-20. Using the pyuca.Collator.sort\_key method.

>>> import pyuca
>>> coll = pyuca.Collator()
>>> fruits = ['caju', 'atemoia', 'cajá', 'açaí', 'acerola']
>>> sorted\_fruits = sorted(fruits, key=coll.sort\_key)
>>> sorted\_fruits
['açaí', 'acerola', 'atemoia', 'cajá', 'caju']
~~~

### 유니코드 데이터베이스
- unicodedata 모듈을 사용한다.
- 수많은 유니코드를 대조한 데이터베이스 형를 제공하며 출력가능성, 데이터 형 등을 알 수 있다.
- re 모듈은 유니코드를 잘 인식하지 못한다.
- regex(PyPi에서 제공) 모듈을 유니코드를 잘 인식한다.

~~~
Example 4-21. Demo of Unicode database numerical character metadata. Callouts de‐scribe each column in the output.

import unicodedata
import re
re\_digit = re.compile(r'\d')
sample = '1\xbc\xb2\u0969\u136b\u216b\u2466\u2480\u3285'
for char in sample:
print('U+%04x' % ord(char),
      char.center(6),
      're_dig' if re_digit.match(char) else '-',
      'isdig' if char.isdigit() else '-',
      'isnum' if char.isnumeric() else '-',
      format(unicodedata.numeric(char), '5.2f'),
      unicodedata.name(char),
      sep='\t')
~~~

### 이중 모드 str 및 bytes API
- bytes: \d, \w 같으 아스키 문자만 매칭된다.
- str  : 아스키, 유니코드, 숫자, 문자 등이 매칭된다.

#### os모듈 함수에서 str과 bytes
- GNU/Linux 커널은 유니코드를 모른다.
- sys.getfilesystemencoding()로 지정된 코덱을 이용해 장동으로 변환되고 동일 코덱으로 디코딩된다.
- 안통한다면 bytes 인수를 os함수에 전달하고 반환된 bytes를 사용할 수 있다.
- os에서 위와같은 문제를 지원하기 아래와 같은 함수를 지원한다.
 - fsencode() : str -\> bytes
 - fsdecode() : bytes -\> str
 - 문자가 깨졌다면 surrogateescape를 사용하여 처리한다.

