---
layout: post
title: "텍스트와바이트"
author: "Polishedwh"
---

## 텍스트와 바이트

### 문자 문제
- 파이썬에서 문자열을 자룰 때에는 문자 '형식'(Encoding type)으로 인한 문제가 발생 할 수 있다．
  - é 와 같은 유니코드 문자는 utf-8 포멧에서 ２바이트를 차지한다．
  - 하지만 인코딩 전의 문자는 1바이트로 나타나기 때문에 이런 요소로 인해 문자열 연산에 문제가 생길 우려가 있다.

{% highlight python %}
>>> s = 'café' # 4개 문자 각 1바이트 예상
>>> len(s)
4 # 길이는 4로 나타남
>>> b = s.encode('utf8') # utf8로 인코딩
>>> b
b'caf\xc3\xa9'
>>> len(b)
5 # 길이가 5로 나타남
>>> b.decode('utf8') # 디코딩
'café'
{% endhighlight %}


### 바이트에 대한 기본 지식
- 파이썬3 에서는 string을 다루기 위해 ２가지 바이너리 시퀀스 타입을 제공한다.

| 타입     | 성질  | 버전 | etc                                                                   |
| bytes    | 불변형| 3.0  | str = b'문자열' 형태로 bytes 문자열 객체를 만들 수 있다.              |
| bytearray| 가변형| 2.6  | str = bytearray(elements) 형태로 bytearray 문자열 객체를 만들 수 있다.|

- 공통점 
  - bytes, bytearray는 format(), format_map()제외하고 str 객체가 지원하는 메소드를 모두 지원한다.
    - endswith, replace, strip, translate, upper, dozens 등
  - re, regex 모듈을 사용할 수 있다.
  - index로 접근하면 0~256사이의 상수가 반환된다.
  - slice로 접근하면 각 형태의 객체)가 반환된다.
    -  b'', bytearray(b'') 

- 차이점
  - 2.6에서도 bytes 형식을 지원하지만 bytearray와 이름만 다를 뿐 내부 구조는 같다. 
  - bytearray 를 slice로 접근하면 elements가 bytes타입인 bytearray객체를 반환한다.
    -  bytearray(b'') 

- 바이트 값의 출력 형태
  - 화면에 표시 가능한 문자는 그대로 출력된다.
  - 개행, cr, tab 등은 \t 와 같이 이스케이프 문자가 붙은 형태로 출력된다.
  - 이외 문자는 \00 처럼 16진수로 형식으로 출력된다.

{% highlight python %}
>>> cafe = bytes('café', encoding='utf_8')
>>> cafe
b'caf\xc3\xa9'
>>> cafe[0]
99
>>> cafe[:1] 
b'c'
>>> cafe_arr = bytearray(cafe) # bytes 객체를 인자로 넘김
>>> cafe_arr
bytearray(b'caf\xc3\xa9')
>>> cafe_arr[-1:]
bytearray(b'\xa9')
{% endhighlight %}

### 기본 인코더/ 디코더
- 파이썬은 utf-8 포멧을 기본 인코딩 포멧으로 제공한다. 
- utf-8 포멧은 모든 유니코드 코드 포인트를 처리 할 수 있다.
- 파이썬은 utf-8외에도 다양한 텍스트 포멧을 encoding/decoding 할 수 있도록 코덱을 제공한다.

### 인코딩/ 디코딩 문제 이해하기

#### UnicodeEncodeError
- 인코딩중 인코딩 대상 문자가 없을때 이 오류가 발생한다.
- 인코딩 옵션 
  - ignore : 오류가 발생해도 별도의 오류 메시지 없이 진행한다. 
  - replace : 오류가 발생한 문자를 ?(물음표 문자)로 치환한다.
  - xmlcharrefreplace: 오류가 발생한 문자를 xml스타일로 치환한다. 

{% highlight python %}
>>> city = 'São Paulo'
>>> city.encode('utf_8')
b'S\xc3\xa3o Paulo'
>>> city.encode('utf_16')
b'\xff\xfeS\x00\xe3\x00o\x00 \x00P\x00a\x00u\x00l\x00o\x00'
>>> city.encode('iso8859_1')
b'S\xe3o Paulo'
>>> city.encode('cp437')
Traceback (most recent call last):
   File "<stdin>", line 1, in <module>
   File "/.../lib/python3.4/encodings/cp437.py", line 12, in encode
   return codecs.charmap_encode(input,errors,encoding_map)
UnicodeEncodeError: 'charmap' codec can't encode character '\xe3' in
position 1: character maps to <undefined>
>>> city.encode('cp437', errors='ignore')
b'So Paulo'
>>> city.encode('cp437', errors='replace')
b'S?o Paulo'
>>> city.encode('cp437', errors='xmlcharrefreplace')
b'S&#227;o Paulo'
{% endhighlight %}

#### UnicodeDecodeError
- 바이트 시퀀스를 텍스트 문자로 변환 할 수 없을때 발생한다.
- 8비트 코덱(cp1252, iso8859_1) 등은 오류없이 멋대로 디코딩하므로 주의가 필요하다.

{% highlight python %}
>>> octets = b'Montr\xe9al'
>>> octets.decode('cp1252')
'Montréal'
>>> octets.decode('iso8859_7')
'Montrιal'
>>> octets.decode('koi8_r')
'MontrИal'
>>> octets.decode('utf_8')
Traceback (most recent call last):
    File "<stdin>", line 1, in <module>
UnicodeDecodeError: 'utf-8' codec can't decode byte 0xe9 in position 5:
invalid continuation byte
>>> octets.decode('utf_8', errors='replace')
'Montr�al'
{% endhighlight %}

#### 예상과 달리 인코딩된 모듈을 로딩할 때 발생하는 SyntaxError
- 파이썬은 2.5는 아스키, 3부터는 utf-8을 소스 코드 기본 인코딩 방식으로 사용한다.
- 인코딩 선언이 필요하다(# coding: utf-8. 없을 경우 오류가 발생 할 수 있다.

{% highlight python %}
# coding: cp1252
{% endhighlight %}

#### 바이트 인코딩 알아내는 방법
- 없다.
- 경험적인 방법을 통해 유추하거나 Chardet 모듈을 통해 30가지 정도는 확인 할 수 있다.
- b'\x20\x00' 바이트 시퀀스가 자주 나타난다면 utf-16le 인코딩에서 공백 문자일 가능 성이 있다 등.

#### BOM(Byte Order Mark)
- utf-16에서 빅엔디안과 리틀엔디안 구분에 사용된다.
  - zero width no-break space(U+FFF)를 인코딩된 텍스트 앞에 붙는다. 이 문자가 없다면 리틀엔디안으로 본다.
  - 출력시에는 보이지 않는다.
  - 엔디언 문제는 utf-16, utf-32에만 영향이 있다.
  - utf-8은 영향을 주지 않는다. 엔디언 특성과 상관없이 동일한 바이트 시퀀스를 생성하기 때문이다.
  - 리틀엔디안에서는 U+FFF가 b'\xff\xfe'로 나타난다.
    - utf-16le, utf-16be등 변형된 형태로 명시하는 경우가 있는데 이때는 U+FFF를 제거하고 가져온다.

### 텍스트 파일 다루기
- 입력할때 bytes를 str로 변환한다.
- str객체로 로직을 수행한다.
- str을 bytes로 변환해서 출력한다.
- python 3에서는 open()에서 위 세 가지 시퀀스를 알아서 처리한다.

- open()
  - open()시 인코딩에 주의하자, 파일을 인코딩한 포멧으로 오픈해야한다.
  - open('example.txt', encoding='utf_8')할때는 인코딩을 지정해서 하자, 기본 인코딩은 os마다 다를 수 있기 때문이다.

- 기본 인코딩
  - 기본 인코딩은 사용하지 않는편이 낫다.
  - 기본 인코딩 설정은 윈도우(다양)와 리눅스(utf-8)의 경우에 많은 부분에서 다르다.
    - locale.getpreferredencoding() 함수가 반환하는 설정이 중요하다. 텍스트 파일을 열 때 기본적으로 사용되기 때문이다.
    - locale.getpreferredencoding() 마저도 참고 할만한 값일 뿐이기때문에 기본인코딩은 사용하지 않는것이 좋다.

### 제대로 비교하기 위해 유니코드 정규화하기
- 유니코드 표준에는 é와 'e\u0301'을 동일하다고 명시하지만 파이썬에서는 다르다고 인식한다.
- unicodedata.normalize()함수가 제공하는 유니코드 정규화로 해결한다.
- 아래 내용은 위키피디아 [유니코드 정규화]항목을 발췌하였다.

- 일반 문자
- NFD로의 정규화 : 코드를 정준 분해한다
  - NFD: 발음기호가 있는 문자 => 발음기호+ 문자
  - À (U+00C0) → A (U+0041) + ̀ (U+0300)

- NFC로의 정규화 : 코드를 정준 분해한 뒤에 다시 정준 결합한다.
  - NFC: 발음기호+ 문자 => 발음기호가 있는 문자(NFD로 분해한 뒤 다시 결합)
  - A (U+0041) + ̀ (U+0300) → À (U+00C0)

- 호환 문자
  - NFKD로의 정규화 : 코드를 호환 분해한다.
  - 합자 처리된 알파벳 코드를 각 알파벳으로 분해하기
    - ﬁ (U+FB01) → f (U+0066) + i (U+0069)
    - 옛 알파벳을 현대 알파벳으로 바꾸기
    - ſ (U+017F) → s (U+0073)

- NFKC로의 정규화 : 코드를 호환 분해한 뒤에 다시 정준 결합한다.
  - 발음 구별 기호가 있는 옛 알파벳을 현대 알파벳으로 바꾸기
  - ẛ (U+1E9B) → ṡ (U+1E61)

#### 케이스 폴딩
- 모든 문자를 소문자로 변환한다.
- str.casefold() 형식으로 사용한다.

- lower와의 차이
  - 유니코드 문자도 변형하여 제공하며, 다양한 기능을 제공한다.
  - 유니코드를 비교 할 때 nfc_equal(), fold_equl() 등의 도구를 이용 할 수 있다.

{% highlight python %}
>>> micro = 'μ'
>>> name(micro)
'MICRO SIGN'
>>> micro_cf = micro.casefold()
>>> name(micro_cf)
'GREEK SMALL LETTER MU'
>>> micro, micro_cf
('μ', 'μ')
>>> eszett = 'ß'
>>> name(eszett)
'LATIN SMALL LETTER SHARP S'
>>> eszett_cf = eszett.casefold()
>>> eszett, eszett_cf
('ß', 'ss')
{% endhighlight %}

#### 발음기호 제거하기
- 발음 기호를 제거해서 사용하는 방법도 때로는(url등)에서 유용할 수 있다.
- 발음 기호를 건너 뛰는 방법
- NFD로 분해 후 발음기호를 건너 뛴다.

- 아래 코드는 발음 기호를 모두 제거한다.
{% highlight python %}
import unicodedata
import string

def shave_marks(txt):
    """Remove all diacritic marks"""
    norm_txt = unicodedata.normalize('NFD', txt)
    shaved = ''.join(c for c in norm_txt
                     if not unicodedata.combining(c))
    return unicodedata.normalize('NFC', shaved)
{% endhighlight %}

- 아래 코드는 그리스(발음기호가 제거되면 않되는) 문자는 변경하지 않는다.
{% highlight python %}
def shave_marks_latin(txt):
    """Remove all diacritic marks from Latin base characters"""
    norm_txt = unicodedata.normalize('NFD', txt)
    latin_base = False
    keepers = []
    for c in norm_txt:
        if unicodedata.combining(c) and latin_base:
            continue # ignore diacritic on Latin base char
        keepers.append(c)

        #if it isn't combining char, it's a new base char
        if not unicodedata.combining(c):
            latin_base = c in string.ascii_letters
    shaved = ''.join(keepers)
    return unicodedata.normalize('NFC', shaved) 
{% endhighlight %}

- 기호를 아스키로 모두 바꿔버린다.
{% highlight python %}
single_map = str.maketrans("""‚ƒ„†ˆ‹‘’“”•–—˜›""",
                           """'f"*^<''""---~>""") # char to char 변환 테이블
multi_map = str.maketrans({
    '€': '<euro>',
    '…': '...',
    'Œ': 'OE',
    '™': '(TM)',
    'œ': 'oe',
    '‰': '<per mille>',
    '‡': '**',
}) # char to string 변환 테이블

multi_map.update(single_map) # 위 두 테이블 머지

def dewinize(txt):
    """Replace Win1252 symbols with ASCII chars or sequences"""
    return txt.translate(multi_map)
def asciize(txt):
    no_marks = shave_marks_latin(dewinize(txt))
    no_marks = no_marks.replace('ß', 'ss')
    return unicodedata.normalize('NFKC', no_marks) 
{% endhighlight %}

### 유니코드 텍스트 정렬하기
- 파이썬에서는 항목 하나 하나를 비교한다.
- 유니코드 정렬시에는 문제가 발생 할 수 있다.

- 파이썬에서 비 아스키 문자는 locale.strxfrm()함수를 이용해서 변환 하는 것이 표준이다.
- 문자열을 현지어와 비교해서 사용할 수 있는 문자열로 변경한다.

- 단, 어플리케이션에서 현지어를 설정(setlocale)하고 os가 지원 해야 한다.
  - 시스템 전역에 영향을 미치므로 신중해야 한다.
  - os에서 setlocale을 제대로 구현하지 않았을 수도 있다.

#### 유니코드 대조 알고리즘을 이용한 정렬
- PyUCA를 사용한다.
- 지역 정보를 고려하지 않으며 정렬 방식을 커스터마이즈 할 수 있다.

{% highlight python %}
>>> import pyuca
>>> coll = pyuca.Collator()
>>> fruits = ['caju', 'atemoia', 'cajá', 'açaí', 'acerola']
>>> sorted_fruits = sorted(fruits, key=coll.sort_key)
>>> sorted_fruits
['açaí', 'acerola', 'atemoia', 'cajá', 'caju']
{% endhighlight %}

#### 유니코드 대조 알고리즘을 이용한 정렬
- PyUCA를 사용한다.
- 지역 정보를 고려하지 않으며 정렬 방식을 커스터마이즈 할 수 있다.

{% highlight python %}
>>> import pyuca
>>> coll = pyuca.Collator()
>>> fruits = ['caju', 'atemoia', 'cajá', 'açaí', 'acerola']
>>> sorted_fruits = sorted(fruits, key=coll.sort_key)
>>> sorted_fruits
['açaí', 'acerola', 'atemoia', 'cajá', 'caju']
{% endhighlight %}

### 유니코드 데이터베이스
- unicodedata 모듈을 사용한다.
- 수많은 유니코드를 대조한 데이터베이스 형를 제공하며 출력가능성, 데이터 형 등을 알 수 있다.
- isdigit, isnumeric등 이미 제공되는 함수들이 유니코드 데이터 베이스 모듈을 사용하고 있다.

{% highlight python %}
import unicodedata
import re
re_digit = re.compile(r'\d')
sample = '1\xbc\xb2\u0969\u136b\u216b\u2466\u2480\u3285'
for char in sample:
print('U+%04x' % ord(char),
      char.center(6),
      're_dig' if re_digit.match(char) else '-',
      'isdig' if char.isdigit() else '-',
      'isnum' if char.isnumeric() else '-',
      format(unicodedata.numeric(char), '5.2f'),
      unicodedata.name(char),
      sep='\t')
{% endhighlight %}

### 이중 모드 str 및 bytes API
- bytes: \d, \w 같으 아스키 문자만 매칭된다.
- str  : 아스키, 유니코드, 숫자, 문자 등이 매칭된다.

#### os모듈 함수에서 str과 bytes
- GNU/Linux 커널은 유니코드를 모른다.
- 따라서 파일명이나 경로명 등을 다루는 os모듈은  str이나 bytes 로 인수를 받는다.
- 넘겨준 인수는 sys.getfilesystemencoding()함수가 지정된 코덱을 이용해 encoding/decoding한다.
  - 이 방법으로 처리하지 못하는 문자가 있다면  bytes 인수를 os함수에 전달하고 반환된 bytes를 사용할 수 있다.
    - fsencode() : str -\> bytes
    - fsdecode() : bytes -\> str
- 오류 처리
  - bytes를 그대로 다루기 때문에 예기치 않은 문제가 발생할 수 있어 아래와 같은 에러 처리기를 제공한다.
    - GNU/Linux : surrogateescape
    - Windows   : strict

[유니코드 정규화]:https://ko.wikipedia.org/wiki/%EC%9C%A0%EB%8B%88%EC%BD%94%EB%93%9C_%EC%A0%95%EA%B7%9C%ED%99%94
